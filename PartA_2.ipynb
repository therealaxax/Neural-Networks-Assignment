{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bdc351",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497557a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30926b92",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "298c40ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c266a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc945183",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tempo  total_beats  average_beats  chroma_stft_mean  \\\n",
      "5358    95.703125         1874     187.400000          0.567137   \n",
      "642    103.359375          477      79.500000          0.549953   \n",
      "7565    78.302557          875     125.000000          0.646271   \n",
      "9584   112.347147         3430     201.764706          0.599859   \n",
      "9374   198.768029         6870     214.687500          0.724747   \n",
      "...           ...          ...            ...               ...   \n",
      "7813   151.999081         3349     176.263158          0.591543   \n",
      "10955  107.666016         3107     194.187500          0.514742   \n",
      "905    161.499023        16138     375.302326          0.492115   \n",
      "5192    92.285156          247      61.750000          0.526634   \n",
      "235     95.703125          602      86.000000          0.500863   \n",
      "\n",
      "       chroma_stft_var  chroma_cq_mean  chroma_cq_var  chroma_cens_mean  \\\n",
      "5358          0.088985        0.515726       0.076869          0.262738   \n",
      "642           0.088597        0.488051       0.072914          0.261439   \n",
      "7565          0.054740        0.475754       0.066636          0.259040   \n",
      "9584          0.076681        0.494668       0.085328          0.256567   \n",
      "9374          0.043357        0.539541       0.058360          0.263587   \n",
      "...                ...             ...            ...               ...   \n",
      "7813          0.071940        0.528416       0.065232          0.270272   \n",
      "10955         0.092520        0.511646       0.074506          0.271299   \n",
      "905           0.093797        0.469686       0.078947          0.263121   \n",
      "5192          0.099779        0.491312       0.074828          0.265789   \n",
      "235           0.088452        0.395492       0.093293          0.241050   \n",
      "\n",
      "       chroma_cens_var  melspectrogram_mean  ...  mfcc15_var  mfcc16_mean  \\\n",
      "5358          0.014302             0.015899  ...  117.286774     6.089151   \n",
      "642           0.014983             0.018391  ...  111.303917     3.540125   \n",
      "7565          0.016232             0.124626  ...   49.751530     0.434910   \n",
      "9584          0.017507             0.004477  ...   62.477417    -3.350802   \n",
      "9374          0.013855             0.014140  ...   58.752964    -2.410653   \n",
      "...                ...                  ...  ...         ...          ...   \n",
      "7813          0.010286             0.032054  ...  164.046249    -0.369736   \n",
      "10955         0.009730             0.040926  ...  102.433891     6.218508   \n",
      "905           0.014101             0.019817  ...   65.280060    -2.093727   \n",
      "5192          0.012689             0.164569  ...  107.594589    -3.633551   \n",
      "235           0.025228             0.192166  ...  120.908699    -4.513874   \n",
      "\n",
      "       mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  \\\n",
      "5358    84.147858    -2.422905   67.536301    -4.414438   58.760742   \n",
      "642     60.906502     1.795746   82.610077    -2.166018   77.132889   \n",
      "7565    47.341629    -0.417416   65.334297    -1.891326   72.152039   \n",
      "9584    67.107170    -3.099106   70.017227    -3.497207   53.586472   \n",
      "9374    48.343849     5.383557   52.549114    -4.578301   51.342655   \n",
      "...           ...          ...         ...          ...         ...   \n",
      "7813    89.608910     2.543516   68.398201    -5.682937  110.162849   \n",
      "10955   62.830105    -4.612158   68.126984    -0.780457   64.284851   \n",
      "905     60.009510    -1.603222   57.384533    -4.032818   58.510933   \n",
      "5192    59.098770    -4.288532   50.693542    -5.702360   67.433617   \n",
      "235     92.010963    -3.100434   92.593933    -9.613089   92.431259   \n",
      "\n",
      "       mfcc19_mean  mfcc19_var  label  \n",
      "5358      2.859649   57.288010      0  \n",
      "642      -0.994072   82.454002      1  \n",
      "7565      3.552524   44.058418      1  \n",
      "9584     -4.491953   59.188267      0  \n",
      "9374      4.329215   50.392876      0  \n",
      "...            ...         ...    ...  \n",
      "7813     -0.494317   67.964111      1  \n",
      "10955    -2.875442   70.085495      0  \n",
      "905      -0.537293   63.688316      0  \n",
      "5192     -4.019995   47.300236      0  \n",
      "235      -5.749306   81.220169      1  \n",
      "\n",
      "[8439 rows x 78 columns]\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP, CustomDataset, loss_fn, split_dataset\n",
    "# from common_utils import split_dataset, preprocess_dataset\n",
    "\n",
    "# def preprocess(df):\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     X_train, y_train, X_test, y_test = split_dataset(df, 'filename', 0.30, 1)\n",
    "#     X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)\n",
    "    \n",
    "#     return X_train_scaled, y_train, X_test_scaled, y_test\n",
    "\n",
    "# import the x train and y train datasets\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "\n",
    "df['label'].value_counts()\n",
    "#change to train test split?\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, 'filename', 0.30, 1)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "class BatchCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# X_train_scaled, y_train, X_test_scaled, y_test = preprocess(df)\n",
    "# X_train, y_train = X_train_scaled, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d4e30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d14410e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d94ae3a1",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6751\n",
      "77\n",
      "[[-0.49106531  0.01265512  0.05686221 ...  1.18119068 -0.38849754\n",
      "  -1.03574435]\n",
      " [-0.79797693 -0.98345107 -0.22072241 ...  0.05499416  0.55841098\n",
      "   0.96548922]\n",
      " [-0.71053897 -0.56340629  1.33516163 ...  1.38367374 -0.88628092\n",
      "   0.96548922]\n",
      " ...\n",
      " [ 2.64264068  1.74732306 -1.15502705 ...  0.18848147 -0.14767633\n",
      "  -1.03574435]\n",
      " [-0.8485064  -1.1473147  -0.59740884 ... -0.8292896  -0.76430263\n",
      "  -1.03574435]\n",
      " [-0.77051526 -0.92344468 -1.01371018 ... -1.33465669  0.51198613\n",
      "   0.96548922]]\n",
      "4\n",
      "5\n",
      "1688\n",
      "77\n",
      "[[-0.82343749 -1.10706956 -0.41688652 ... -0.16468361 -0.68326526\n",
      "  -1.02763283]\n",
      " [ 0.98136812  2.11967717  0.5703326  ...  1.19125302 -0.5304174\n",
      "  -1.02763283]\n",
      " [ 2.26269824  1.56816612 -0.46104367 ... -0.4657886  -0.76811365\n",
      "  -1.02763283]\n",
      " ...\n",
      " [-0.84217921 -1.13612265 -1.27788254 ... -0.73719861  0.23449046\n",
      "   0.97311021]\n",
      " [-0.82817678 -1.14106785  0.41268208 ...  0.68536118 -0.9647467\n",
      "  -1.02763283]\n",
      " [-0.6952614  -0.71454386 -0.90409557 ...  0.72641355 -0.53359531\n",
      "   0.97311021]]\n",
      "4\n",
      "5\n",
      "6751\n",
      "[0 1 1 ... 0 0 1]\n",
      "1\n",
      "4\n",
      "5\n",
      "1688\n",
      "[0 0 0 ... 1 0 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "#     x train scaled and y train goes in here\n",
    "#     x train scaled dict is the list of of 4/5 matrices\n",
    "#     x val scaled dict is the last 1/5 matrix for testing\n",
    "#     y train dict is the list of 4/5 labels\n",
    "#     y val dict is the last 1/5 labels for testing\n",
    "    \n",
    "#     It will not differ by batch size. X_train_scaled_dict[128] is a list of train dataset for the different folds, and you should have 5 elements in the list in total. It is the same as X_train_scaled_dict[256], etc\n",
    "#     X_train_scaled_dict should look like {128:[list of 5 folds] 256:[list of 5 folds], 512: [list of 5 folds], 1024: [list of 5 folds]}\n",
    "#     y_train_dict is a dictionary of 4x5 elements as well, each element is the matrix of labels to train towards\n",
    "    \n",
    "#     customdataset = xtrain, ytrain\n",
    "    \n",
    "#     cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "#     for train_idx, test_idx in cv.split(X_train, y_train):\n",
    "#         X_train_scaled_dict, y_train_dict  = X_train[train_idx], y_train[train_idx]\n",
    "#         X_val_scaled_dict, y__val_dict = X_train[test_idx], y_train[test_idx]\n",
    "    batch_sizes = parameters  # Default to batch size of 32 if not provided\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "#     X_train_scaled_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "#     X_val_scaled_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "#     y_train_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "#     y_val_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "\n",
    "    X_train_scaled_dict = {}\n",
    "    X_val_scaled_dict = {}\n",
    "    y_train_dict = {}\n",
    "    y_val_dict = {}\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        X_train_scaled_dict[batch_size] = []\n",
    "        X_val_scaled_dict[batch_size] = []\n",
    "        y_train_dict[batch_size] = []\n",
    "        y_val_dict[batch_size] = []\n",
    "    \n",
    "    X_train = X_train[:, 1:]\n",
    "    for train_idx, val_idx in cv.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        standard_scaler = preprocessing.StandardScaler()\n",
    "        X_train_fold_scaled = standard_scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = standard_scaler.fit_transform(X_val_fold)\n",
    "        \n",
    "        for batch_size in batch_sizes:\n",
    "            X_train_scaled_dict[batch_size].append(X_train_fold_scaled)\n",
    "            X_val_scaled_dict[batch_size].append(X_val_fold_scaled)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            y_val_dict[batch_size].append(y_val_fold)\n",
    "    \n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128,256,512,1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)\n",
    "# sanity check: note that 6751 / 8439 is around 80%\n",
    "# print(X_train_scaled_dict)\n",
    "print(len(X_train_scaled_dict))\n",
    "print(len(X_train_scaled_dict[128]))\n",
    "print(len(X_train_scaled_dict[128][0]))\n",
    "print(len(X_train_scaled_dict[256][2][0]))\n",
    "print(X_train_scaled_dict[128][0])\n",
    "\n",
    "# sanity check: this is the other 20%\n",
    "# print(X_val_scaled_dict)\n",
    "print(len(X_val_scaled_dict))\n",
    "print(len(X_val_scaled_dict[128]))\n",
    "print(len(X_val_scaled_dict[128][0]))\n",
    "print(len(X_val_scaled_dict[256][2][0]))\n",
    "print(X_val_scaled_dict[128][0])\n",
    "\n",
    "# print(y_train_dict)\n",
    "print(len(y_train_dict))\n",
    "print(len(y_train_dict[128]))\n",
    "print(len(y_train_dict[128][0]))\n",
    "print(y_train_dict[128][0])\n",
    "print(y_train_dict[128][0][1])\n",
    "\n",
    "# print(y_val_dict)\n",
    "print(len(y_val_dict))\n",
    "print(len(y_val_dict[128]))\n",
    "print(len(y_val_dict[128][0]))\n",
    "print(y_val_dict[128][0])\n",
    "print(y_val_dict[128][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2fc69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6723fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8f45d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "23f82d1a",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999776448843614]\n",
      "[5.96801495552063]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999776448843614, 0.998144508532758]\n",
      "[5.96801495552063, 5.120497465133667]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999776448843614, 0.998144508532758, 0.999809981517072]\n",
      "[5.96801495552063, 5.120497465133667, 4.215728998184204]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999776448843614, 0.998144508532758, 0.999809981517072, 1.0]\n",
      "[5.96801495552063, 5.120497465133667, 4.215728998184204, 4.004384517669678]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999776448843614, 0.998144508532758, 0.999809981517072, 1.0, 0.9999888156944851]\n",
      "[5.96801495552063, 5.120497465133667, 4.215728998184204, 4.004384517669678, 4.187382936477661]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9998902943399217]\n",
      "[2.494239568710327]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9998902943399217, 1.0]\n",
      "[2.494239568710327, 3.2124834060668945]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9998902943399217, 1.0, 0.9999780588679843]\n",
      "[2.494239568710327, 3.2124834060668945, 2.427781105041504]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9998902943399217, 1.0, 0.9999780588679843, 1.0]\n",
      "[2.494239568710327, 3.2124834060668945, 2.427781105041504, 2.8823816776275635]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9998902943399217, 1.0, 0.9999780588679843, 1.0, 1.0]\n",
      "[2.494239568710327, 3.2124834060668945, 2.427781105041504, 2.8823816776275635, 2.3591556549072266]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999576849596841]\n",
      "[1.5529866218566895]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999576849596841, 1.0]\n",
      "[1.5529866218566895, 1.7287111282348633]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999576849596841, 1.0, 1.0]\n",
      "[1.5529866218566895, 1.7287111282348633, 1.588524341583252]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999576849596841, 1.0, 1.0, 0.9999576849596841]\n",
      "[1.5529866218566895, 1.7287111282348633, 1.588524341583252, 1.5021321773529053]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9999576849596841, 1.0, 1.0, 0.9999576849596841, 1.0]\n",
      "[1.5529866218566895, 1.7287111282348633, 1.588524341583252, 1.5021321773529053, 1.5147006511688232]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[1.0]\n",
      "[1.0790681838989258]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[1.0, 1.0]\n",
      "[1.0790681838989258, 1.1204309463500977]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[1.0, 1.0, 1.0]\n",
      "[1.0790681838989258, 1.1204309463500977, 1.2300622463226318]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[1.0, 1.0, 1.0, 1.0]\n",
      "[1.0790681838989258, 1.1204309463500977, 1.2300622463226318, 1.1411573886871338]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "an epoch17\n",
      "an epoch18\n",
      "an epoch19\n",
      "an epoch20\n",
      "an epoch21\n",
      "an epoch22\n",
      "an epoch23\n",
      "an epoch24\n",
      "an epoch25\n",
      "an epoch26\n",
      "an epoch27\n",
      "an epoch28\n",
      "an epoch29\n",
      "an epoch30\n",
      "an epoch31\n",
      "an epoch32\n",
      "an epoch33\n",
      "an epoch34\n",
      "an epoch35\n",
      "an epoch36\n",
      "an epoch37\n",
      "an epoch38\n",
      "an epoch39\n",
      "an epoch40\n",
      "an epoch41\n",
      "an epoch42\n",
      "an epoch43\n",
      "an epoch44\n",
      "an epoch45\n",
      "an epoch46\n",
      "an epoch47\n",
      "an epoch48\n",
      "an epoch49\n",
      "an epoch50\n",
      "an epoch51\n",
      "an epoch52\n",
      "an epoch53\n",
      "an epoch54\n",
      "an epoch55\n",
      "an epoch56\n",
      "an epoch57\n",
      "an epoch58\n",
      "an epoch59\n",
      "an epoch60\n",
      "an epoch61\n",
      "an epoch62\n",
      "an epoch63\n",
      "an epoch64\n",
      "an epoch65\n",
      "an epoch66\n",
      "an epoch67\n",
      "an epoch68\n",
      "an epoch69\n",
      "an epoch70\n",
      "an epoch71\n",
      "an epoch72\n",
      "an epoch73\n",
      "an epoch74\n",
      "an epoch75\n",
      "an epoch76\n",
      "an epoch77\n",
      "an epoch78\n",
      "an epoch79\n",
      "an epoch80\n",
      "an epoch81\n",
      "an epoch82\n",
      "an epoch83\n",
      "an epoch84\n",
      "an epoch85\n",
      "an epoch86\n",
      "an epoch87\n",
      "an epoch88\n",
      "an epoch89\n",
      "an epoch90\n",
      "an epoch91\n",
      "an epoch92\n",
      "an epoch93\n",
      "an epoch94\n",
      "an epoch95\n",
      "an epoch96\n",
      "an epoch97\n",
      "an epoch98\n",
      "an epoch99\n",
      "[0.9995841901257354, 0.9999736706415812, 0.9999830739838735, 1.0]\n",
      "[4.699201774597168, 2.6752082824707033, 1.5774109840393067, 1.148944091796875]\n"
     ]
    }
   ],
   "source": [
    "def intialise_loaders_batch(X_train_scaled, y_train, X_test_scaled, y_test, batch_size):\n",
    "\n",
    "#     print(\"X_train_scaled in initialise loaders batch\")\n",
    "#     print(len(X_train_scaled[0]))\n",
    "    train_data = BatchCustomDataset(X_train_scaled,y_train)\n",
    "#     print(len(train_data[1]))\n",
    "    test_data = BatchCustomDataset(X_test_scaled,y_test)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "def train_loop_batch(dataloader, model, loss_fn, optimizer, x_test, y_test):\n",
    "    # put within the epochs loop\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     print(size)\n",
    "#     print(num_batches)\n",
    "#     train_loss, train_correct = 0, 0\n",
    "    acc_ = []\n",
    "#     print\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "#         print(len(X[0]))\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(len(x_test[0]))\n",
    "        pred = model(torch.tensor(x_test, dtype=torch.float))\n",
    "#         print(pred)\n",
    "#         print(y_test)\n",
    "#         acc__ = (pred.argmax(1) == torch.tensor(y_test, dtype=torch.float).argmax(1)).type(torch.float).mean()\n",
    "        acc__ = (pred.argmax(1) == torch.tensor(y_test, dtype=torch.float)).type(torch.float).mean()\n",
    "        \n",
    "        acc_.append(acc__.item())\n",
    "        \n",
    "    return acc_\n",
    "#         train_loss += loss.item()\n",
    "#         train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "#     train_loss /= num_batches\n",
    "#     train_correct /=size\n",
    "\n",
    "#     return train_loss, train_correct\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes):\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "    model = MLP(77,128,2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    cross_validation_times = []\n",
    "#     acc = []\n",
    "    foldaccuracyofabatchsize = []\n",
    "    timeforafoldforthatbatchsize = []\n",
    "    meanaccuracyofabatchsizelist = []\n",
    "    meantimeofabatchsizelist = []\n",
    "    for batch_size in batch_sizes:\n",
    "        print(foldaccuracyofabatchsize)\n",
    "        print(timeforafoldforthatbatchsize)\n",
    "        foldaccuracyofabatchsize = []\n",
    "        timeforafoldforthatbatchsize = []\n",
    "        for idxy in range(0,5):\n",
    "            x_train = X_train_scaled_dict[batch_size][idxy]\n",
    "            y_train = y_train_dict[batch_size][idxy]\n",
    "            x_test = X_val_scaled_dict[batch_size][idxy]\n",
    "            y_test = y_val_dict[batch_size][idxy]\n",
    "            print(foldaccuracyofabatchsize)\n",
    "            print(timeforafoldforthatbatchsize)\n",
    "#             acc_ = []\n",
    "#             time = []\n",
    "#             print(len(x_train[0]))\n",
    "            train_dataloader, test_dataloader = intialise_loaders_batch(x_train, y_train, x_test, y_test, batch_size)\n",
    "#             print(train_dataloader.dataset)\n",
    "            for epoch in range(100):\n",
    "                start = time.time()\n",
    "                acc_ = train_loop_batch(train_dataloader, model, loss_fn, optimizer, x_test, y_test)\n",
    "                end = time.time()\n",
    "                # for a fold, the list of accuracies for the batches of that epoch^\n",
    "                print(\"an epoch\" + str(epoch))\n",
    "                if epoch==99:\n",
    "                    foldaccuracyofabatchsize.append(np.mean(np.array(acc_), axis = 0))\n",
    "#                     the accuracy for the last epoch of that fold - the fold accuracy for that batch size, length is 5\n",
    "                    timeforafoldforthatbatchsize.append(end-start)\n",
    "        meanaccuracyofabatchsizelist.append(np.mean(np.array(foldaccuracyofabatchsize), axis = 0))\n",
    "        meantimeofabatchsizelist.append(np.mean(np.array(timeforafoldforthatbatchsize), axis = 0))\n",
    "        # length should be 4^\n",
    "\n",
    "#         acc_ = []\n",
    "#         for no_hidden in hidden_units:\n",
    "        \n",
    "#             model = FFN(no_inputs, no_hidden, no_outputs)\n",
    "    \n",
    "#             loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#             optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "#             for epoch in range(100):\n",
    "#                 pred = model(torch.tensor(x_train, dtype=torch.float))\n",
    "#                 loss = loss_fn(pred, torch.tensor(y_train, dtype=torch.float))\n",
    "    \n",
    "#                 # Backpropagation\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "    \n",
    "#             pred = model(torch.tensor(x_test, dtype=torch.float))\n",
    "#             acc__ = (pred.argmax(1) == torch.tensor(y_test, dtype=torch.float).argmax(1)).type(torch.float).mean()\n",
    "    \n",
    "#             acc_.append(acc__.item())\n",
    "#             accuracylistfor5foldsforabatchsize.append(acc_)\n",
    "#         acc.append(accuracylistfor5foldsforabatchsize.mean)\n",
    "#         acc.append(acc_)\n",
    "    \n",
    "#     cv_acc = np.mean(np.array(acc), axis = 0)\n",
    "#     cross_validation_accuracies = cv_acc\n",
    "    cross_validation_accuracies = meanaccuracyofabatchsizelist\n",
    "    cross_validation_times = meantimeofabatchsizelist\n",
    "    print(cross_validation_accuracies)\n",
    "    print(cross_validation_times)\n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "batch_sizes = [128,256,512,1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabb946",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e733b37c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f23aefbe",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# plt.figure(1)\n",
    "plt.plot(batch_sizes, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.title('mean cross-validation accuracy for different batch sizes')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('mean CV accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55f4a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5711062f",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.699202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>2.675208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>1.577411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.148944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         4.699202\n",
       "1         256         2.675208\n",
       "2         512         1.577411\n",
       "3        1024         1.148944"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time': cross_validation_times\n",
    "                  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce4b61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "550a0798",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 1024\n",
    "reason = \"Lowest last epoch time and highest mean cross-validation accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5636a30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
