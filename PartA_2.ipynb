{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffd569c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16f74b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4af9b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8393b23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6dc656",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "31f5f062",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tempo  total_beats  average_beats  chroma_stft_mean  \\\n",
      "5358    95.703125         1874     187.400000          0.567137   \n",
      "642    103.359375          477      79.500000          0.549953   \n",
      "7565    78.302557          875     125.000000          0.646271   \n",
      "9584   112.347147         3430     201.764706          0.599859   \n",
      "9374   198.768029         6870     214.687500          0.724747   \n",
      "...           ...          ...            ...               ...   \n",
      "7813   151.999081         3349     176.263158          0.591543   \n",
      "10955  107.666016         3107     194.187500          0.514742   \n",
      "905    161.499023        16138     375.302326          0.492115   \n",
      "5192    92.285156          247      61.750000          0.526634   \n",
      "235     95.703125          602      86.000000          0.500863   \n",
      "\n",
      "       chroma_stft_var  chroma_cq_mean  chroma_cq_var  chroma_cens_mean  \\\n",
      "5358          0.088985        0.515726       0.076869          0.262738   \n",
      "642           0.088597        0.488051       0.072914          0.261439   \n",
      "7565          0.054740        0.475754       0.066636          0.259040   \n",
      "9584          0.076681        0.494668       0.085328          0.256567   \n",
      "9374          0.043357        0.539541       0.058360          0.263587   \n",
      "...                ...             ...            ...               ...   \n",
      "7813          0.071940        0.528416       0.065232          0.270272   \n",
      "10955         0.092520        0.511646       0.074506          0.271299   \n",
      "905           0.093797        0.469686       0.078947          0.263121   \n",
      "5192          0.099779        0.491312       0.074828          0.265789   \n",
      "235           0.088452        0.395492       0.093293          0.241050   \n",
      "\n",
      "       chroma_cens_var  melspectrogram_mean  ...  mfcc15_var  mfcc16_mean  \\\n",
      "5358          0.014302             0.015899  ...  117.286774     6.089151   \n",
      "642           0.014983             0.018391  ...  111.303917     3.540125   \n",
      "7565          0.016232             0.124626  ...   49.751530     0.434910   \n",
      "9584          0.017507             0.004477  ...   62.477417    -3.350802   \n",
      "9374          0.013855             0.014140  ...   58.752964    -2.410653   \n",
      "...                ...                  ...  ...         ...          ...   \n",
      "7813          0.010286             0.032054  ...  164.046249    -0.369736   \n",
      "10955         0.009730             0.040926  ...  102.433891     6.218508   \n",
      "905           0.014101             0.019817  ...   65.280060    -2.093727   \n",
      "5192          0.012689             0.164569  ...  107.594589    -3.633551   \n",
      "235           0.025228             0.192166  ...  120.908699    -4.513874   \n",
      "\n",
      "       mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  \\\n",
      "5358    84.147858    -2.422905   67.536301    -4.414438   58.760742   \n",
      "642     60.906502     1.795746   82.610077    -2.166018   77.132889   \n",
      "7565    47.341629    -0.417416   65.334297    -1.891326   72.152039   \n",
      "9584    67.107170    -3.099106   70.017227    -3.497207   53.586472   \n",
      "9374    48.343849     5.383557   52.549114    -4.578301   51.342655   \n",
      "...           ...          ...         ...          ...         ...   \n",
      "7813    89.608910     2.543516   68.398201    -5.682937  110.162849   \n",
      "10955   62.830105    -4.612158   68.126984    -0.780457   64.284851   \n",
      "905     60.009510    -1.603222   57.384533    -4.032818   58.510933   \n",
      "5192    59.098770    -4.288532   50.693542    -5.702360   67.433617   \n",
      "235     92.010963    -3.100434   92.593933    -9.613089   92.431259   \n",
      "\n",
      "       mfcc19_mean  mfcc19_var  label  \n",
      "5358      2.859649   57.288010      0  \n",
      "642      -0.994072   82.454002      1  \n",
      "7565      3.552524   44.058418      1  \n",
      "9584     -4.491953   59.188267      0  \n",
      "9374      4.329215   50.392876      0  \n",
      "...            ...         ...    ...  \n",
      "7813     -0.494317   67.964111      1  \n",
      "10955    -2.875442   70.085495      0  \n",
      "905      -0.537293   63.688316      0  \n",
      "5192     -4.019995   47.300236      0  \n",
      "235      -5.749306   81.220169      1  \n",
      "\n",
      "[8439 rows x 78 columns]\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP, CustomDataset, loss_fn, split_dataset\n",
    "# from common_utils import split_dataset, preprocess_dataset\n",
    "\n",
    "# def preprocess(df):\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     X_train, y_train, X_test, y_test = split_dataset(df, 'filename', 0.30, 1)\n",
    "#     X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)\n",
    "    \n",
    "#     return X_train_scaled, y_train, X_test_scaled, y_test\n",
    "\n",
    "# import the x train and y train datasets\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "\n",
    "df['label'].value_counts()\n",
    "#change to train test split?\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, 'filename', 0.30, 1)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "class BatchCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# X_train_scaled, y_train, X_test_scaled, y_test = preprocess(df)\n",
    "# X_train, y_train = X_train_scaled, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69730a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "561c0a9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dafdd184",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6751\n",
      "77\n",
      "[[-0.49106531  0.01265512  0.05686221 ...  1.18119068 -0.38849754\n",
      "  -1.03574435]\n",
      " [-0.79797693 -0.98345107 -0.22072241 ...  0.05499416  0.55841098\n",
      "   0.96548922]\n",
      " [-0.71053897 -0.56340629  1.33516163 ...  1.38367374 -0.88628092\n",
      "   0.96548922]\n",
      " ...\n",
      " [ 2.64264068  1.74732306 -1.15502705 ...  0.18848147 -0.14767633\n",
      "  -1.03574435]\n",
      " [-0.8485064  -1.1473147  -0.59740884 ... -0.8292896  -0.76430263\n",
      "  -1.03574435]\n",
      " [-0.77051526 -0.92344468 -1.01371018 ... -1.33465669  0.51198613\n",
      "   0.96548922]]\n",
      "4\n",
      "5\n",
      "1688\n",
      "77\n",
      "[[-0.82343749 -1.10706956 -0.41688652 ... -0.16468361 -0.68326526\n",
      "  -1.02763283]\n",
      " [ 0.98136812  2.11967717  0.5703326  ...  1.19125302 -0.5304174\n",
      "  -1.02763283]\n",
      " [ 2.26269824  1.56816612 -0.46104367 ... -0.4657886  -0.76811365\n",
      "  -1.02763283]\n",
      " ...\n",
      " [-0.84217921 -1.13612265 -1.27788254 ... -0.73719861  0.23449046\n",
      "   0.97311021]\n",
      " [-0.82817678 -1.14106785  0.41268208 ...  0.68536118 -0.9647467\n",
      "  -1.02763283]\n",
      " [-0.6952614  -0.71454386 -0.90409557 ...  0.72641355 -0.53359531\n",
      "   0.97311021]]\n",
      "4\n",
      "5\n",
      "6751\n",
      "[0 1 1 ... 0 0 1]\n",
      "1\n",
      "4\n",
      "5\n",
      "1688\n",
      "[0 0 0 ... 1 0 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "#     x train scaled and y train goes in here\n",
    "#     x train scaled dict is the list of of 4/5 matrices\n",
    "#     x val scaled dict is the last 1/5 matrix for testing\n",
    "#     y train dict is the list of 4/5 labels\n",
    "#     y val dict is the last 1/5 labels for testing\n",
    "    \n",
    "#     It will not differ by batch size. X_train_scaled_dict[128] is a list of train dataset for the different folds, and you should have 5 elements in the list in total. It is the same as X_train_scaled_dict[256], etc\n",
    "#     X_train_scaled_dict should look like {128:[list of 5 folds] 256:[list of 5 folds], 512: [list of 5 folds], 1024: [list of 5 folds]}\n",
    "#     y_train_dict is a dictionary of 4x5 elements as well, each element is the matrix of labels to train towards\n",
    "    \n",
    "#     customdataset = xtrain, ytrain\n",
    "    \n",
    "#     cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "#     for train_idx, test_idx in cv.split(X_train, y_train):\n",
    "#         X_train_scaled_dict, y_train_dict  = X_train[train_idx], y_train[train_idx]\n",
    "#         X_val_scaled_dict, y__val_dict = X_train[test_idx], y_train[test_idx]\n",
    "    batch_sizes = parameters  # Default to batch size of 32 if not provided\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "#     X_train_scaled_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "#     X_val_scaled_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "#     y_train_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "#     y_val_dict = {batch_size: [] for batch_size in batch_sizes}\n",
    "\n",
    "    X_train_scaled_dict = {}\n",
    "    X_val_scaled_dict = {}\n",
    "    y_train_dict = {}\n",
    "    y_val_dict = {}\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        X_train_scaled_dict[batch_size] = []\n",
    "        X_val_scaled_dict[batch_size] = []\n",
    "        y_train_dict[batch_size] = []\n",
    "        y_val_dict[batch_size] = []\n",
    "    \n",
    "    X_train = X_train[:, 1:]\n",
    "    for train_idx, val_idx in cv.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        standard_scaler = preprocessing.StandardScaler()\n",
    "        X_train_fold_scaled = standard_scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = standard_scaler.fit_transform(X_val_fold)\n",
    "        \n",
    "        for batch_size in batch_sizes:\n",
    "            X_train_scaled_dict[batch_size].append(X_train_fold_scaled)\n",
    "            X_val_scaled_dict[batch_size].append(X_val_fold_scaled)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            y_val_dict[batch_size].append(y_val_fold)\n",
    "    \n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128,256,512,1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)\n",
    "# sanity check: note that 6751 / 8439 is around 80%\n",
    "# print(X_train_scaled_dict)\n",
    "print(len(X_train_scaled_dict))\n",
    "print(len(X_train_scaled_dict[128]))\n",
    "print(len(X_train_scaled_dict[128][0]))\n",
    "print(len(X_train_scaled_dict[256][2][0]))\n",
    "print(X_train_scaled_dict[128][0])\n",
    "\n",
    "# sanity check: this is the other 20%\n",
    "# print(X_val_scaled_dict)\n",
    "print(len(X_val_scaled_dict))\n",
    "print(len(X_val_scaled_dict[128]))\n",
    "print(len(X_val_scaled_dict[128][0]))\n",
    "print(len(X_val_scaled_dict[256][2][0]))\n",
    "print(X_val_scaled_dict[128][0])\n",
    "\n",
    "# print(y_train_dict)\n",
    "print(len(y_train_dict))\n",
    "print(len(y_train_dict[128]))\n",
    "print(len(y_train_dict[128][0]))\n",
    "print(y_train_dict[128][0])\n",
    "print(y_train_dict[128][0][1])\n",
    "\n",
    "# print(y_val_dict)\n",
    "print(len(y_val_dict))\n",
    "print(len(y_val_dict[128]))\n",
    "print(len(y_val_dict[128][0]))\n",
    "print(y_val_dict[128][0])\n",
    "print(y_val_dict[128][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76d792",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7b495",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8d2f70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dcbfa9b4",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9997764488436142]\n",
      "[3.9894590377807617]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9997764488436142, 0.9998770468639877]\n",
      "[3.9894590377807617, 3.92329478263855]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9997764488436142, 0.9998770468639877, 0.9996646732654212]\n",
      "[3.9894590377807617, 3.92329478263855, 4.331712961196899]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9997764488436142, 0.9998770468639877, 0.9996646732654212, 0.9999888224421807]\n",
      "[3.9894590377807617, 3.92329478263855, 4.331712961196899, 4.087543487548828]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9997764488436142, 0.9998770468639877, 0.9996646732654212, 0.9999888224421807, 1.0]\n",
      "[3.9894590377807617, 3.92329478263855, 4.331712961196899, 4.087543487548828, 3.9498097896575928]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9998025298118591]\n",
      "[2.3899080753326416]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9998025298118591, 1.0]\n",
      "[2.3899080753326416, 2.4868364334106445]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9998025298118591, 1.0, 1.0]\n",
      "[2.3899080753326416, 2.4868364334106445, 2.3579342365264893]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9998025298118591, 1.0, 1.0, 1.0]\n",
      "[2.3899080753326416, 2.4868364334106445, 2.3579342365264893, 2.661369562149048]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9998025298118591, 1.0, 1.0, 1.0, 1.0]\n",
      "[2.3899080753326416, 2.4868364334106445, 2.3579342365264893, 2.661369562149048, 2.291290760040283]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0]\n",
      "[1.607438325881958]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0]\n",
      "[1.607438325881958, 1.6157782077789307]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0, 1.0]\n",
      "[1.607438325881958, 1.6157782077789307, 1.809626579284668]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0, 1.0, 1.0]\n",
      "[1.607438325881958, 1.6157782077789307, 1.809626579284668, 1.5625040531158447]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.607438325881958, 1.6157782077789307, 1.809626579284668, 1.5625040531158447, 1.6018447875976562]\n",
      "[]\n",
      "[]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0]\n",
      "[1.1378443241119385]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0]\n",
      "[1.1378443241119385, 1.3051187992095947]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0, 1.0]\n",
      "[1.1378443241119385, 1.3051187992095947, 1.1608545780181885]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[1.0, 1.0, 1.0, 1.0]\n",
      "[1.1378443241119385, 1.3051187992095947, 1.1608545780181885, 1.1523051261901855]\n",
      "an epoch0\n",
      "an epoch1\n",
      "an epoch2\n",
      "an epoch3\n",
      "an epoch4\n",
      "an epoch5\n",
      "an epoch6\n",
      "an epoch7\n",
      "an epoch8\n",
      "an epoch9\n",
      "an epoch10\n",
      "an epoch11\n",
      "an epoch12\n",
      "an epoch13\n",
      "an epoch14\n",
      "an epoch15\n",
      "an epoch16\n",
      "[0.9998613982830408, 0.9999605059623718, 1.0, 1.0]\n",
      "[4.0563640117645265, 2.4374678134918213, 1.6394383907318115, 1.1826510429382324]\n"
     ]
    }
   ],
   "source": [
    "def intialise_loaders_batch(X_train_scaled, y_train, X_test_scaled, y_test, batch_size):\n",
    "\n",
    "#     print(\"X_train_scaled in initialise loaders batch\")\n",
    "#     print(len(X_train_scaled[0]))\n",
    "    train_data = BatchCustomDataset(X_train_scaled,y_train)\n",
    "#     print(len(train_data[1]))\n",
    "    test_data = BatchCustomDataset(X_test_scaled,y_test)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "def train_loop_batch(dataloader, model, loss_fn, optimizer, x_test, y_test):\n",
    "    # put within the epochs loop\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     print(size)\n",
    "#     print(num_batches)\n",
    "#     train_loss, train_correct = 0, 0\n",
    "    acc_ = []\n",
    "#     print\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "#         print(len(X[0]))\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(len(x_test[0]))\n",
    "        pred = model(torch.tensor(x_test, dtype=torch.float))\n",
    "#         print(pred)\n",
    "#         print(y_test)\n",
    "#         acc__ = (pred.argmax(1) == torch.tensor(y_test, dtype=torch.float).argmax(1)).type(torch.float).mean()\n",
    "        acc__ = (pred.argmax(1) == torch.tensor(y_test, dtype=torch.float)).type(torch.float).mean()\n",
    "        \n",
    "        acc_.append(acc__.item())\n",
    "        \n",
    "    return acc_\n",
    "#         train_loss += loss.item()\n",
    "#         train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "#     train_loss /= num_batches\n",
    "#     train_correct /=size\n",
    "\n",
    "#     return train_loss, train_correct\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes):\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "    model = MLP(77,128,2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    cross_validation_times = []\n",
    "#     acc = []\n",
    "    foldaccuracyofabatchsize = []\n",
    "    timeforafoldforthatbatchsize = []\n",
    "    meanaccuracyofabatchsizelist = []\n",
    "    meantimeofabatchsizelist = []\n",
    "    for batch_size in batch_sizes:\n",
    "        print(foldaccuracyofabatchsize)\n",
    "        print(timeforafoldforthatbatchsize)\n",
    "        foldaccuracyofabatchsize = []\n",
    "        timeforafoldforthatbatchsize = []\n",
    "        for idxy in range(0,5):\n",
    "            x_train = X_train_scaled_dict[batch_size][idxy]\n",
    "            y_train = y_train_dict[batch_size][idxy]\n",
    "            x_test = X_val_scaled_dict[batch_size][idxy]\n",
    "            y_test = y_val_dict[batch_size][idxy]\n",
    "            print(foldaccuracyofabatchsize)\n",
    "            print(timeforafoldforthatbatchsize)\n",
    "#             acc_ = []\n",
    "#             time = []\n",
    "#             print(len(x_train[0]))\n",
    "            train_dataloader, test_dataloader = intialise_loaders_batch(x_train, y_train, x_test, y_test, batch_size)\n",
    "#             print(train_dataloader.dataset)\n",
    "            for epoch in range(17):\n",
    "                start = time.time()\n",
    "                acc_ = train_loop_batch(train_dataloader, model, loss_fn, optimizer, x_test, y_test)\n",
    "                end = time.time()\n",
    "                # for a fold, the list of accuracies for the batches of that epoch^\n",
    "                print(\"an epoch\" + str(epoch))\n",
    "                if epoch==16:\n",
    "                    foldaccuracyofabatchsize.append(np.mean(np.array(acc_), axis = 0))\n",
    "#                     the accuracy for the last epoch of that fold - the fold accuracy for that batch size, length is 5\n",
    "                    timeforafoldforthatbatchsize.append(end-start)\n",
    "        meanaccuracyofabatchsizelist.append(np.mean(np.array(foldaccuracyofabatchsize), axis = 0))\n",
    "        meantimeofabatchsizelist.append(np.mean(np.array(timeforafoldforthatbatchsize), axis = 0))\n",
    "        # length should be 4^\n",
    "\n",
    "#         acc_ = []\n",
    "#         for no_hidden in hidden_units:\n",
    "        \n",
    "#             model = FFN(no_inputs, no_hidden, no_outputs)\n",
    "    \n",
    "#             loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#             optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "#             for epoch in range(100):\n",
    "#                 pred = model(torch.tensor(x_train, dtype=torch.float))\n",
    "#                 loss = loss_fn(pred, torch.tensor(y_train, dtype=torch.float))\n",
    "    \n",
    "#                 # Backpropagation\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "    \n",
    "#             pred = model(torch.tensor(x_test, dtype=torch.float))\n",
    "#             acc__ = (pred.argmax(1) == torch.tensor(y_test, dtype=torch.float).argmax(1)).type(torch.float).mean()\n",
    "    \n",
    "#             acc_.append(acc__.item())\n",
    "#             accuracylistfor5foldsforabatchsize.append(acc_)\n",
    "#         acc.append(accuracylistfor5foldsforabatchsize.mean)\n",
    "#         acc.append(acc_)\n",
    "    \n",
    "#     cv_acc = np.mean(np.array(acc), axis = 0)\n",
    "#     cross_validation_accuracies = cv_acc\n",
    "    cross_validation_accuracies = meanaccuracyofabatchsizelist\n",
    "    cross_validation_times = meantimeofabatchsizelist\n",
    "    print(cross_validation_accuracies)\n",
    "    print(cross_validation_times)\n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "batch_sizes = [128,256,512,1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e46c16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d47b3e20",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb641748",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# plt.figure(1)\n",
    "plt.plot(batch_sizes, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.title('mean cross-validation accuracy for different batch sizes')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('mean CV accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e59fae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3fd9a623",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.056364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>2.437468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>1.639438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.182651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         4.056364\n",
       "1         256         2.437468\n",
       "2         512         1.639438\n",
       "3        1024         1.182651"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time': cross_validation_times\n",
    "                  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad71bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a3829ca4",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 1024\n",
    "reason = \"Lowest last epoch time and highest mean cross-validation accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1750f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
