{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp6KAX1UXqaK"
   },
   "source": [
    "CS4001/4042 Assignment 1, Part B, Q4\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsfKoCAMj9uo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rjdf67uIarDX"
   },
   "source": [
    "Your co-investigators used a linear regression model to rapidly test out several combinations of train/test splits and shared with you their findings in a brief report attached in Appendix A below. You wish to investigate whether your deep learning model corroborates with their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3-BW2LW4Icq"
   },
   "outputs": [],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "E7dD3Ihi4GF9"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJjXNMOqcHVJ"
   },
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fOUcXL5OXASY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 23:46:30,528 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n",
      "Global seed set to 42\n",
      "2023-10-10 23:46:30,552 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-10-10 23:46:30,558 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-10-10 23:46:30,637 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-10-10 23:46:30,670 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-10-10 23:46:30,732 - {pytorch_tabular.tabular_model:573} - INFO - Auto LR Find Started\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('valid_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('valid_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cf788dd1e34168815286dc6b6eed6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('train_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at C:\\Users\\Gareth Thong\\Neural Networks and Deep Learning B4\\.lr_find_3dd2798d-753c-4431-adaa-74cd7f54f6a7.ckpt\n",
      "Restored all states from the checkpoint file at C:\\Users\\Gareth Thong\\Neural Networks and Deep Learning B4\\.lr_find_3dd2798d-753c-4431-adaa-74cd7f54f6a7.ckpt\n",
      "2023-10-10 23:46:36,204 - {pytorch_tabular.tabular_model:575} - INFO - Suggested LR: 0.5754399373371567. For plot and detailed analysis, use `find_learning_rate` method.\n",
      "2023-10-10 23:46:36,205 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  2.9 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  2.9 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.5 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.5 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.5 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.5 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7763e49cd664ea7bab616f7c0dc6257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 23:47:17,239 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-10-10 23:47:17,240 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e8e11c8f65432481537b9d5b4ded72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing \n",
       "`Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing \n",
       "`Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by\n",
       "doing `Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by\n",
       "doing `Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       16267038720.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       16267038720.0       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      16267038720.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      16267038720.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ad994b8d0f46bd9c6d139e313d4d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 23:47:20,509 - {pytorch_tabular.tabular_model:129} - INFO - Experiment Tracking is turned off\n",
      "2023-10-10 23:47:20,514 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# This is the model from B1, but using year 2022 as test data.\n",
    "\n",
    "df2020val = df[df['year']==2020]\n",
    "df2022test = df[df['year']==2022]\n",
    "df2019andbeforetrain = df[df['year']<=2019]\n",
    "\n",
    "# Training the model from B1 and evaluating on year 2022 data\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        \"resale_price\"\n",
    "    ],  # target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols= [\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\", \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"],\n",
    "    categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"],\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(optimizer=\"Adam\")\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\",  # Number of nodes in each layer\n",
    "    activation=\"ReLU\"\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=df2019andbeforetrain, validation=df2020val)\n",
    "result = tabular_model.evaluate(df2022test)\n",
    "pred_df = tabular_model.predict(df2022test)\n",
    "tabular_model.save_model(\"Neural Networks and Deep Learning B4 2022\")\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"Neural Networks and Deep Learning B4 2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 127542.29821209553\n",
      "R2 is 0.4388472630514271\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(pred_df['resale_price'], pred_df['resale_price_prediction'], squared=False)\n",
    "print(\"RMSE is \" + str(rmse))\n",
    "\n",
    "# Calculate R^2\n",
    "r2 = r2_score(pred_df['resale_price'], pred_df['resale_price_prediction'])\n",
    "print(\"R2 is \" + str(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsbs0iMiaUy-"
   },
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "B4FLRQfBaRS-"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5923f61bbfa04ada9113b8975e854a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing \n",
       "`Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing \n",
       "`Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by\n",
       "doing `Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by\n",
       "doing `Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       24701364224.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       24701364224.0       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      24701364224.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      24701364224.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3622c63e20547119383e51cf8b3db27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 23:47:54,121 - {pytorch_tabular.tabular_model:129} - INFO - Experiment Tracking is turned off\n",
      "2023-10-10 23:47:54,126 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "df2023test = df[df['year']==2023]\n",
    "\n",
    "result = tabular_model.evaluate(df2023test)\n",
    "pred_df = tabular_model.predict(df2023test)\n",
    "tabular_model.save_model(\"Neural Networks and Deep Learning B4 2023\")\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"Neural Networks and Deep Learning B4 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 157166.677331193\n",
      "R2 is 0.162125913544938\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(pred_df['resale_price'], pred_df['resale_price_prediction'], squared=False)\n",
    "print(\"RMSE is \" + str(rmse))\n",
    "\n",
    "# Calculate R^2\n",
    "r2 = r2_score(pred_df['resale_price'], pred_df['resale_price_prediction'])\n",
    "print(\"R2 is \" + str(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11mU8sxcaSAP"
   },
   "source": [
    "> Did model degradation occur for the deep learning model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nviGacm6aSlf"
   },
   "source": [
    "Yes, model degradation has occurred for the deep learning model. The RMSE and R2 when tested on year 2021 was 76696.923214814 and 0.7776187684416944 respectively. However, the RMSE has increased subsequently for years 2022 and 2023 to 127542.29821209553 and 157166.677331193 respectively, while the R2 value has decreased to 0.4388472630514271 and 0.162125913544938 for years 2022 and 2023 respectively. The greater error and worser model fit indicate model degradation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyiP8gBAcABD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruldtSTDcYzt"
   },
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2019 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nGbdZc3ocYbB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month -- Drift? No! -- Chi2 0.000 -- p-value 1.000\n",
      "town -- Drift? Yes! -- Chi2 667.474 -- p-value 0.000\n",
      "full_address -- Drift? Yes! -- Chi2 1750.200 -- p-value 0.004\n",
      "nearest_stn -- Drift? Yes! -- Chi2 617.871 -- p-value 0.000\n",
      "dist_to_nearest_stn -- Drift? No! -- K-S 0.055 -- p-value 0.094\n",
      "dist_to_dhoby -- Drift? Yes! -- K-S 0.218 -- p-value 0.000\n",
      "degree_centrality -- Drift? No! -- K-S 0.029 -- p-value 0.783\n",
      "eigenvector_centrality -- Drift? Yes! -- K-S 0.195 -- p-value 0.000\n",
      "flat_model_type -- Drift? Yes! -- Chi2 77.586 -- p-value 0.000\n",
      "remaining_lease_years -- Drift? Yes! -- K-S 0.271 -- p-value 0.000\n",
      "floor_area_sqm -- Drift? Yes! -- K-S 0.134 -- p-value 0.000\n",
      "storey_range -- Drift? Yes! -- Chi2 38.800 -- p-value 0.001\n"
     ]
    }
   ],
   "source": [
    "# Note to marker: I have not included \"year\" in the features to be consistent with the model trained previously.\n",
    "\n",
    "X_ref = (df[df['year']<=2019]).drop(columns=['year', 'resale_price'])[:1000]\n",
    "X_test = (df[df['year']==2023]).drop(columns=['year', 'resale_price'])[:1000]\n",
    "categories_per_feature = {0:None, 1:None, 2:None, 3:None, 8:None, 11:None}\n",
    "\n",
    "cd = TabularDrift(X_ref.to_numpy(), p_val=.05, categories_per_feature=categories_per_feature)\n",
    "fpreds = cd.predict(X_test.to_numpy(), drift_type='feature')\n",
    "\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    labels = ['No!', 'Yes!']\n",
    "    feature_names = [\"month\", \"town\", \n",
    "                     \"full_address\", \"nearest_stn\", \"dist_to_nearest_stn\", \n",
    "                     \"dist_to_dhoby\", \"degree_centrality\", \"eigenvector_centrality\", \n",
    "                     \"flat_model_type\", \"remaining_lease_years\", \"floor_area_sqm\", \"storey_range\"]\n",
    "    fname = feature_names[f]\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmj3qq3PkJUf"
   },
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UOsX4JqkZ9S"
   },
   "source": [
    "Concept drift possibly led to model degradation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM2OoOJdkZj1"
   },
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3licBjskdLL"
   },
   "source": [
    "From my analysis, the features which contributed to this shift are town, full_address, nearest_stn, dist_to_dhoby, eigenvector_centrality, flat_model_type, remaining_lease_years, floor_area_sqm and storey_range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB3fSvKskhEJ"
   },
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UpP7K6Tkglx"
   },
   "source": [
    "To address the model degradation and improve test R2 for year 2023, the model could be trained on more recent data using entries from the year 2022 and before as training data. This would take the cooling measures introduced by the Singapore government into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EqFinZObcYXu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 01:05:27,356 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n",
      "Global seed set to 42\n",
      "2023-10-11 01:05:27,386 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-10-11 01:05:27,395 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-10-11 01:05:27,549 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-10-11 01:05:27,587 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-10-11 01:05:27,655 - {pytorch_tabular.tabular_model:573} - INFO - Auto LR Find Started\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory C:\\Users\\Gareth Thong\\Neural Networks and Deep Learning B4\\saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('valid_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('valid_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faac876109d4f84837c4af6bffb7e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You called `self.log('train_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at C:\\Users\\Gareth Thong\\Neural Networks and Deep Learning B4\\.lr_find_bb10184a-da0c-46e7-929a-0e211ab5958b.ckpt\n",
      "Restored all states from the checkpoint file at C:\\Users\\Gareth Thong\\Neural Networks and Deep Learning B4\\.lr_find_bb10184a-da0c-46e7-929a-0e211ab5958b.ckpt\n",
      "2023-10-11 01:05:31,987 - {pytorch_tabular.tabular_model:575} - INFO - Suggested LR: 0.5754399373371567. For plot and detailed analysis, use `find_learning_rate` method.\n",
      "2023-10-11 01:05:31,987 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f321fd77eab45b892d622fcc57b19d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 01:08:05,325 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-10-11 01:08:05,326 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd46d926e7ed47b5985cf968efc40875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing \n",
       "`Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing \n",
       "`Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by\n",
       "doing `Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\core\\module.py:493: UserWarning: You \n",
       "called `self.log('test_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by\n",
       "doing `Trainer(logger=ALogger(...))`\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       13176255488.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       13176255488.0       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      13176255488.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      13176255488.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6482d5f6e3404b46b4375d153f11f290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 01:08:07,268 - {pytorch_tabular.tabular_model:129} - INFO - Experiment Tracking is turned off\n",
      "2023-10-11 01:08:07,279 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "C:\\Users\\Gareth Thong\\anaconda3\\envs\\nnb4\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2023testlastquestion = df[df['year']==2023]\n",
    "df2022andbeforetrainlastquestion = df[df['year']<=2022]\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        \"resale_price\"\n",
    "    ],  # target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols= [\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\", \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"],\n",
    "    categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"],\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(optimizer=\"Adam\")\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\",  # Number of nodes in each layer\n",
    "    activation=\"ReLU\"\n",
    ")\n",
    "\n",
    "tabular_model_last_question = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model_last_question.fit(train=df2022andbeforetrainlastquestion)\n",
    "result_last_question = tabular_model_last_question.evaluate(df2023testlastquestion)\n",
    "pred_df_last_question = tabular_model_last_question.predict(df2023testlastquestion)\n",
    "tabular_model_last_question.save_model(\"Neural Networks and Deep Learning B4 last question\")\n",
    "loaded_model_last_question = TabularModel.load_from_checkpoint(\"Neural Networks and Deep Learning B4 last question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved test R2 for year 2023 is 0.5530593913505556\n"
     ]
    }
   ],
   "source": [
    "# Calculate R^2\n",
    "r2 = r2_score(pred_df_last_question['resale_price'], pred_df_last_question['resale_price_prediction'])\n",
    "print(\"Improved test R2 for year 2023 is \" + str(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQG9hZvAaq5g"
   },
   "source": [
    "### Appendix A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ARi2OxbDuZ"
   },
   "source": [
    "Here are our results from a linear regression model. We used StandardScaler for continuous variables and OneHotEncoder for categorical variables.\n",
    "\n",
    "While 2021 data can be predicted well, test R2 dropped rapidly for 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| Year <= 2020 | 2021     | 0.76    |\n",
    "| Year <= 2020 | **2022**     | 0.41    |\n",
    "| Year <= 2020 | **2023**     | **0.10**   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmv91FqgbI8h"
   },
   "source": [
    "Similarly, a model trained on 2017 data can predict 2018-2021 well (with slight degradation in performance for 2021), but drops drastically in 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2017         | 2018     | 0.90    |\n",
    "|              | 2019     | 0.89    |\n",
    "|              | 2020     | 0.87    |\n",
    "|              | 2021     | 0.72    |\n",
    "|              | **2022**     | **0.37**    |\n",
    "|              | **2023**     | **0.09**    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayKGs106bI6S"
   },
   "source": [
    "With the test set fixed at year 2021, training on data from 2017-2020 still works well on the test data, with minimal degradation. Training sets closer to year 2021 generally do better.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2020         | 2021     | 0.81    |\n",
    "| 2019         | 2021     | 0.75    |\n",
    "| 2018         | 2021     | 0.73    |\n",
    "| 2017         | 2021     | 0.72    |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWUKTcEICJ0j/YcXkGkr53",
   "collapsed_sections": [
    "wQG9hZvAaq5g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
